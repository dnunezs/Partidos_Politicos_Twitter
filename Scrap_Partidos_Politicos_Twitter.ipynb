{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos las cabeceras HTTP y el user agent al detectar la web que accedemos desde python\n",
    "headers = {\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,\\\n",
    "*/*;q=0.8\",\n",
    "\"Accept-Encoding\": \"gzip, deflate, sdch, br\",\n",
    "\"Accept-Language\": \"en-US,en;q=0.8\",\n",
    "\"Cache-Control\": \"no-cache\",\n",
    "\"dnt\": \"1\",\n",
    "\"Pragma\": \"no-cache\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\",\n",
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/5\\\n",
    "37.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Tomamos la informacion de la web\n",
    "soup = requests.get(\"https://socialblade.com/twitter/user/vox_es/monthly\", headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(soup.text, 'lxml')\n",
    "script_divs = soup.find_all('script', {'type': 'text/javascript'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una funcion para coger solo la parte que nos interesa\n",
    "def lista_scrap(x, y):\n",
    "    # Nos quedamos solo con la fila 5 de la lista ya que es donde esta la ifnormacion que queremos\n",
    "    cadena_ori = script_divs[5]\n",
    "    # Creamos una lista separando por [ que es por donde empieza nuestra informacion\n",
    "    cadena_sep = str(cadena_ori).split('[')\n",
    "    # Selecionamos las filas que queremos segun si es seguidores, menos seguidores...\n",
    "    lista = cadena_sep[x:y]\n",
    "    # eliminamos ,]\n",
    "    lista = [test.replace('],', '').replace('\"', '') for test in lista]\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos otra funacion para crear un dataframe con los datos de la anterior funcion\n",
    "def lista_dataf(x, y):\n",
    "    df = pd.DataFrame()\n",
    "    # Usamos la funcion anterior para coger los datos\n",
    "    lista = lista_scrap(x, y)\n",
    "    # Señalamos la primera colunma como la fecha y sacamos los datos de la lista\n",
    "    df['Semana'] = [x.split(',')[0] for x in lista]\n",
    "    # Señalamos la segunda como los seguidores\n",
    "    df['Seguidores'] = [x.split(',')[1] for x in lista]\n",
    "    # Ahora hay que pasar la fecha a un formao mas legible\n",
    "    # Convertir epoch a fecha normal\n",
    "    # tenemos que eliminar los tres ultimos ceros para pasorlo\n",
    "    df['Semana'] = df['Semana'].map(lambda x: str(x)[:-3])\n",
    "    # pasamos la columna a numeros\n",
    "    df['Semana'] = pd.to_numeric(df['Semana'])\n",
    "    # pasamos a formato fecha\n",
    "    for n in range(len(df)):\n",
    "        df['Semana'][n] = datetime.datetime.fromtimestamp(df['Semana'][n]).strftime('%d-%m-%Y')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dany\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Si inspeccionamos los datos vemos de donde a donde van cada uno de los graficos\n",
    "cadena_ori = script_divs[5]\n",
    "cadena_sep = str(cadena_ori).split('[')\n",
    "\n",
    "seguidores_ganados = lista_dataf(3, 182)\n",
    "seguidos_nuevos = lista_dataf(185, 364)\n",
    "media = lista_dataf(367, 546)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Seguidores</th>\n",
       "      <th>Seguidos</th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-05-2017</td>\n",
       "      <td>209</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29-05-2017</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-06-2017</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12-06-2017</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19-06-2017</td>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Semana Seguidores Seguidos Media\n",
       "0  22-05-2017        209        5   113\n",
       "1  29-05-2017         69        7    84\n",
       "2  05-06-2017        107        9   121\n",
       "3  12-06-2017        105        2    71\n",
       "4  19-06-2017         97        8   127"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juantamos las tres variables\n",
    "Base_conjunta = pd.DataFrame()\n",
    "Base_conjunta['Semana'] = seguidores_ganados['Semana']\n",
    "Base_conjunta['Seguidores'] = seguidores_ganados['Seguidores']\n",
    "Base_conjunta['Seguidos'] = seguidos_nuevos['Seguidores']\n",
    "Base_conjunta['Media'] = media['Seguidores']\n",
    "\n",
    "# Vemos la cabecera de la base\n",
    "Base_conjunta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la base en csv\n",
    "Vox_Twitter = Base_conjunta\n",
    "Vox_Twitter.to_csv('Vox_Twitter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dany\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# PODEMOS\n",
    "soup = requests.get(\"https://socialblade.com/twitter/user/podemos/monthly\", headers=headers)\n",
    "soup = bs(soup.text, 'lxml')\n",
    "script_divs = soup.find_all('script', {'type': 'text/javascript'})\n",
    "\n",
    "seguidores_ganados = lista_dataf(3, 230)\n",
    "seguidos_nuevos = lista_dataf(233, 460)\n",
    "media = lista_dataf(463, 690)\n",
    "\n",
    "Base_conjunta = pd.DataFrame()\n",
    "Base_conjunta['Semana'] = seguidores_ganados['Semana']\n",
    "Base_conjunta['Seguidores'] = seguidores_ganados['Seguidores']\n",
    "Base_conjunta['Seguidos'] = seguidos_nuevos['Seguidores']\n",
    "Base_conjunta['Media'] = media['Seguidores']\n",
    "\n",
    "Podemos_Twitter = Base_conjunta\n",
    "\n",
    "Podemos_Twitter = Podemos_Twitter[48:227]\n",
    "\n",
    "Podemos_Twitter.to_csv('Podemos_Twitter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dany\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# PP\n",
    "soup = requests.get(\"https://socialblade.com/twitter/user/populares/monthly\", headers=headers)\n",
    "soup = bs(soup.text, 'lxml')\n",
    "script_divs = soup.find_all('script', {'type': 'text/javascript'})\n",
    "\n",
    "seguidores_ganados = lista_dataf(3, 211)\n",
    "seguidos_nuevos = lista_dataf(214, 423)\n",
    "media = lista_dataf(425, 633)\n",
    "\n",
    "Base_conjunta = pd.DataFrame()\n",
    "Base_conjunta['Semana'] = seguidores_ganados['Semana']\n",
    "Base_conjunta['Seguidores'] = seguidores_ganados['Seguidores']\n",
    "Base_conjunta['Seguidos'] = seguidos_nuevos['Seguidores']\n",
    "Base_conjunta['Media'] = media['Seguidores']\n",
    "\n",
    "PP_Twitter = Base_conjunta\n",
    "PP_Twitter = PP_Twitter[29:208]\n",
    "\n",
    "PP_Twitter.to_csv('PP_Twitter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dany\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# PSOE\n",
    "soup = requests.get(\"https://socialblade.com/twitter/user/PSOE/monthly\", headers=headers)\n",
    "soup = bs(soup.text, 'lxml')\n",
    "script_divs = soup.find_all('script', {'type': 'text/javascript'})\n",
    "\n",
    "seguidores_ganados = lista_dataf(3, 230)\n",
    "seguidos_nuevos = lista_dataf(233, 460)\n",
    "media = lista_dataf(463, 690)\n",
    "\n",
    "Base_conjunta = pd.DataFrame()\n",
    "Base_conjunta['Semana'] = seguidores_ganados['Semana']\n",
    "Base_conjunta['Seguidores'] = seguidores_ganados['Seguidores']\n",
    "Base_conjunta['Seguidos'] = seguidos_nuevos['Seguidores']\n",
    "Base_conjunta['Media'] = media['Seguidores']\n",
    "\n",
    "PSOE_Twitter = Base_conjunta\n",
    "\n",
    "PSOE_Twitter.to_csv('PSOE_Twitter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Seguidores_PSOE</th>\n",
       "      <th>Seguidos_PSOE</th>\n",
       "      <th>Seguidores_Podemos</th>\n",
       "      <th>Seguidos_Podemos</th>\n",
       "      <th>Seguidores_PP</th>\n",
       "      <th>Seguidos_PP</th>\n",
       "      <th>Seguidores_Vox</th>\n",
       "      <th>Seguidos_Vox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>21-09-2020</td>\n",
       "      <td>315</td>\n",
       "      <td>-3</td>\n",
       "      <td>224</td>\n",
       "      <td>-1</td>\n",
       "      <td>3277</td>\n",
       "      <td>2671</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>28-09-2020</td>\n",
       "      <td>355</td>\n",
       "      <td>-5</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>409</td>\n",
       "      <td>-11</td>\n",
       "      <td>1021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>05-10-2020</td>\n",
       "      <td>435</td>\n",
       "      <td>-6</td>\n",
       "      <td>454</td>\n",
       "      <td>2</td>\n",
       "      <td>613</td>\n",
       "      <td>-2</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>12-10-2020</td>\n",
       "      <td>472</td>\n",
       "      <td>-1</td>\n",
       "      <td>493</td>\n",
       "      <td>3</td>\n",
       "      <td>652</td>\n",
       "      <td>-33</td>\n",
       "      <td>817</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>19-10-2020</td>\n",
       "      <td>988</td>\n",
       "      <td>-6</td>\n",
       "      <td>992</td>\n",
       "      <td>6</td>\n",
       "      <td>-387</td>\n",
       "      <td>-234</td>\n",
       "      <td>2048</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Semana Seguidores_PSOE Seguidos_PSOE Seguidores_Podemos  \\\n",
       "223  21-09-2020             315            -3                224   \n",
       "224  28-09-2020             355            -5                 84   \n",
       "225  05-10-2020             435            -6                454   \n",
       "226  12-10-2020             472            -1                493   \n",
       "227  19-10-2020             988            -6                992   \n",
       "\n",
       "    Seguidos_Podemos Seguidores_PP Seguidos_PP Seguidores_Vox Seguidos_Vox  \n",
       "223               -1          3277        2671            255            2  \n",
       "224                2           409         -11           1021            4  \n",
       "225                2           613          -2            623            0  \n",
       "226                3           652         -33            817           -3  \n",
       "227                6          -387        -234           2048           -1  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntamos las cuatro bases y dejamos solo seguidores y seguidos\n",
    "Partidos_Twitter = pd.DataFrame()\n",
    "\n",
    "# Eliminamos la media ya que no nos aporta\n",
    "PSOE_Twitter.drop(['Media'], axis = 'columns', inplace=True)\n",
    "Podemos_Twitter.drop(['Media'], axis = 'columns', inplace=True)\n",
    "Vox_Twitter.drop(['Media'], axis = 'columns', inplace=True)\n",
    "PP_Twitter.drop(['Media'], axis = 'columns', inplace=True)\n",
    "\n",
    "# Al juntarlos vemos que hay algunas semanas que no coincide exactamente y no se juntan bien.\n",
    "PSOE_Twitter.Semana[77] = '11-12-2017'\n",
    "PP_Twitter.Semana[58] = '11-12-2017'\n",
    "Vox_Twitter.Semana[11] = '07-08-2017'  \n",
    "Vox_Twitter.Semana[16] = '11-09-2017'\n",
    "Vox_Twitter.Semana[29] = '18-12-2017'\n",
    "Vox_Twitter.Semana[44] = '26-03-2018'\n",
    "\n",
    "# Juntamos las bases en una conjunta\n",
    "Partidos_Twitter = pd.merge(PSOE_Twitter, Podemos_Twitter, on='Semana', how='outer', suffixes=( '_PSOE', '_Podemos'))\n",
    "Partidos_Twitter = pd.merge(Partidos_Twitter, PP_Twitter, on='Semana', how='outer', suffixes=( '_prueba', '_PP'))\n",
    "Partidos_Twitter = pd.merge(Partidos_Twitter, Vox_Twitter, on='Semana', how='outer', suffixes=( '_PP', '_Vox'))\n",
    "\n",
    "Partidos_Twitter.to_csv('Partidos_Politicos_Twitter.csv', index=False)\n",
    "\n",
    "Partidos_Twitter.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
